{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_curve, PrecisionRecallDisplay\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import gensim\n",
    "import torch\n",
    "import gensim.downloader as gloader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current work directory: {Path.cwd()}\")\n",
    "dataset_folder = Path.cwd().joinpath(\"dependency_treebank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splits\n",
    "\n",
    "The corpus contains 200 documents.\n",
    "\n",
    "   * **Train**: Documents 1-100\n",
    "   * **Validation**: Documents 101-150\n",
    "   * **Test**: Documents 151-199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for file_path in dataset_folder.glob('*.dp'):            \n",
    "    with file_path.open(mode='r', encoding='utf-8') as text:\n",
    "        lines = text.read().split('\\n')\n",
    "        words = []\n",
    "        tags = []\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) == 3:\n",
    "                word, tag, _ = parts\n",
    "                words.append(word)\n",
    "                tags.append(tag)\n",
    "        data.append([(words, tags)])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([Pierre, Vinken, ,, 61, years, old, ,, will, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([Rudolph, Agnew, ,, 55, years, old, and, form...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([A, form, of, asbestos, once, used, to, make,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([Yields, on, money-market, mutual, funds, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([J.P., Bolduc, ,, vice, chairman, of, W.R., G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([Pacific, First, Financial, Corp., said, shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([McDermott, International, Inc., said, its, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([The, federal, government, suspended, sales, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>([Clark, J., Vitulli, was, named, senior, vice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>([When, it, 's, time, for, their, biannual, po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 doc\n",
       "0  ([Pierre, Vinken, ,, 61, years, old, ,, will, ...\n",
       "1  ([Rudolph, Agnew, ,, 55, years, old, and, form...\n",
       "2  ([A, form, of, asbestos, once, used, to, make,...\n",
       "3  ([Yields, on, money-market, mutual, funds, con...\n",
       "4  ([J.P., Bolduc, ,, vice, chairman, of, W.R., G...\n",
       "5  ([Pacific, First, Financial, Corp., said, shar...\n",
       "6  ([McDermott, International, Inc., said, its, B...\n",
       "7  ([The, federal, government, suspended, sales, ...\n",
       "8  ([Clark, J., Vitulli, was, named, senior, vice...\n",
       "9  ([When, it, 's, time, for, their, biannual, po..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Build vocabulary\n",
    "def build_vocabulary(df: pd.DataFrame):\n",
    "    word_to_idx = OrderedDict()\n",
    "    tag_to_idx = OrderedDict()\n",
    "    \n",
    "    word_idx = 0\n",
    "    tag_idx = 0\n",
    "\n",
    "    for doc in df.doc.values:\n",
    "        tokens = doc[0]\n",
    "        tags = doc[1]\n",
    "        for token in tokens:\n",
    "            if token not in word_to_idx:\n",
    "                word_to_idx[token] = word_idx\n",
    "                word_idx += 1\n",
    "        for tag in tags:\n",
    "            if tag not in tag_to_idx:\n",
    "                tag_to_idx[tag] = tag_idx\n",
    "                tag_idx +=1\n",
    "\n",
    "    # Add [UNK] token for OOV words\n",
    "    word_to_idx[\"[UNK]\"] = word_idx\n",
    "\n",
    "    return word_to_idx, tag_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: 100\n",
      "Validation set shape: 50\n",
      "Test set shape: 49\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "train_split = df[0:100]\n",
    "val_split = df[100:150].reset_index(drop=True)\n",
    "test_split = df[150:199].reset_index(drop=True)\n",
    "\n",
    "# Display the shapes of the sets\n",
    "print(\"Training set shape:\", len(train_split))\n",
    "print(\"Validation set shape:\", len(val_split))\n",
    "print(\"Test set shape:\", len(test_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global vocabulary -> Tags size: 45\n",
      "Global vocabulary -> Index vocabulary size: 11969\n",
      "Training vocabulary-> Tags size: 45\n",
      "Training vocabulary -> Index vocabulary size: 8010\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary and tags, word-to-index format\n",
    "global_vocab, global_tags = build_vocabulary(df)\n",
    "train_vocab, train_tags = build_vocabulary(train_split)\n",
    "\n",
    "print(f'Global vocabulary -> Tags size: {len(global_tags)}')\n",
    "print(f'Global vocabulary -> Index vocabulary size: {len(global_vocab)}')\n",
    "\n",
    "print(f'Training vocabulary-> Tags size: {len(train_tags)}')\n",
    "print(f'Training vocabulary -> Index vocabulary size: {len(train_vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(',', 1),\n",
       "             ('.', 10),\n",
       "             ('``', 26),\n",
       "             (\"''\", 28),\n",
       "             (':', 30),\n",
       "             ('$', 33),\n",
       "             ('-LRB-', 36),\n",
       "             ('-RRB-', 37),\n",
       "             ('#', 44)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excluded_tags = OrderedDict(filter(lambda i: i[0] in [',', '.', '``', '\\'\\'', ':', '$', '-LRB-', '-RRB-', '#'], global_tags.items()))\n",
    "excluded_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a neural POS tagger, you first need to encode text into numerical format.\n",
    "\n",
    "Words are embedded using **GloVe embeddings**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = gloader.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total OOV terms: 3746 (31.30%)\n"
     ]
    }
   ],
   "source": [
    "def get_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
    "                  word_to_idx):\n",
    "    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
    "    oov = set(word_to_idx.keys()).difference(embedding_vocabulary)\n",
    "    return list(oov)\n",
    "\n",
    "oov_terms = get_OOV_terms(emb_model, global_vocab)\n",
    "oov_percentage = float(len(oov_terms)) * 100 / len(set(global_vocab.keys()))\n",
    "print(f\"Total OOV terms: {len(oov_terms)} ({oov_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_word(word, train_vocab, embedding_model, embedding_dimension):\n",
    "    try:\n",
    "        return torch.squeeze(torch.tensor(embedding_model[word]))\n",
    "    except (KeyError):\n",
    "        # Except catch embeddings not present in Glove\n",
    "        if word in train_vocab.keys() and word != \"[UNK]\":\n",
    "            # OOV embedding for training set, in the training set we should have an embedding for oov words\n",
    "            return torch.tensor(np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension), dtype=torch.float32)\n",
    "        else:\n",
    "            if word == \"[UNK]\":\n",
    "                return torch.zeros(embedding_dimension)\n",
    "\n",
    "def build_embedding_matrix(global_vocab, train_vocab, embedding_model, embedding_dimension):\n",
    "    '''\n",
    "        I am also building the final vocabulary with the words in the dataset minus the OOV in test/validation\n",
    "        The OOV of the training are instead kept with a specific embedding\n",
    "    '''\n",
    "    t = []\n",
    "    vocab = OrderedDict()\n",
    "    idx = 0\n",
    "\n",
    "    for w in global_vocab:\n",
    "        e = embed_word(w, train_vocab, embedding_model, embedding_dimension)\n",
    "        if e is not None:\n",
    "            vocab[w] = idx\n",
    "            idx +=1\n",
    "            t.append(e)\n",
    "    return torch.stack(t), vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embedding matrix\n",
    "train_emb_matrix, final_vocab = build_embedding_matrix(global_vocab, train_vocab, emb_model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "torch.all(torch.eq(torch.tensor(emb_model[\"major\"]), train_emb_matrix[final_vocab[\"major\"]])) and torch.all(torch.eq(torch.tensor(emb_model[\"street\"]), train_emb_matrix[final_vocab[\"street\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10570, 100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb_matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3244,  0.8465, -0.5692, -0.3774,  1.0488, -1.0676, -0.3345,  0.0499,\n",
      "         0.7326,  0.2384,  1.2318,  0.0164,  0.9287, -0.5538,  0.6091, -0.7560,\n",
      "        -0.3821,  0.8602, -0.1405, -0.0408,  0.2743, -0.0973,  1.1942,  0.1475,\n",
      "        -0.3266, -0.1162, -0.2708,  0.8588, -0.2909,  0.8833,  0.8562,  0.5291,\n",
      "        -0.2573,  0.3494,  0.9375,  0.8830, -0.2655, -0.5822,  0.2148, -0.0814,\n",
      "         0.4326, -0.8328, -0.3314,  0.3622,  0.4342,  0.3715,  0.1212, -0.1988,\n",
      "         0.0865,  1.1287, -0.0488,  0.5335, -0.3382,  0.8388,  0.1526, -1.4057,\n",
      "         0.4374, -0.5224,  1.1454,  0.8335, -0.8808,  0.1059,  0.1660,  0.4363,\n",
      "         0.1849,  0.4419, -0.1773, -0.4333,  0.2662, -0.5618, -0.3018,  0.1875,\n",
      "         0.6955, -0.5731,  0.0376, -0.2253,  0.6259,  0.9278,  0.4875, -0.7836,\n",
      "         0.1306, -0.6360, -0.2503,  0.9517, -0.8151,  0.2434,  0.0183,  0.0615,\n",
      "         0.3020, -0.0655,  0.0866,  0.4295, -0.4348,  0.2115, -0.1157, -0.1821,\n",
      "        -0.8717, -0.0289,  1.4115,  0.2803])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(train_emb_matrix[-2])\n",
    "print(train_emb_matrix[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "\n",
    "Define a neural POS tagger.\n",
    "\n",
    "### Models\n",
    "\n",
    "* **Baseline**: Bidirectional LSTM with a Dense layer on top.\n",
    "\n",
    "* **Model 1**: additional LSTM layer to the Baseline model.\n",
    "* **Model 2**: additional Dense layer to the Baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve index from word\n",
    "def word_to_idx_conv(sentence, to_idx):\n",
    "    idxs = []\n",
    "    for w in sentence:\n",
    "        try:\n",
    "            idxs.append(to_idx[w[0]])\n",
    "        except(KeyError):\n",
    "            # Redirect to [UNK], which is always the last of the vocabulary\n",
    "            idxs.append(len(to_idx)-1)\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "def tag_to_idx_conv(tags, to_ix):\n",
    "    idxs = []\n",
    "    for w in tags:      \n",
    "        idxs.append(to_ix[w[0]])\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "# Retrieve tag from index\n",
    "def idx_to_tag_conv(idxs, tag_vocab):\n",
    "    tags = []\n",
    "    vocab = list(tag_vocab.items())\n",
    "    for i in idxs:\n",
    "        tags.append(vocab[i][0])\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: %s' % device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self, embedding_dim, vocab_size, tagset_size, freeze=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_size-1, _freeze=freeze)\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, bidirectional=True)\n",
    "        self.dense1 = nn.Linear(2*embedding_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        \n",
    "        embedded = self.embedding(sentence)\n",
    "        lstm_out, _ = self.lstm1(embedded)\n",
    "        tag_space = self.dense1(lstm_out)\n",
    "        return tag_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(Baseline):\n",
    "    def __init__(self, embedding_dim, vocab_size, tagset_size, freeze):\n",
    "        super().__init__(embedding_dim, vocab_size, tagset_size, freeze)\n",
    "    \n",
    "        self.lstm1 = nn.LSTM(embedding_dim, embedding_dim, 2, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(Baseline):\n",
    "    def __init__(self, embedding_dim, vocab_size, tagset_size, freeze):\n",
    "        super().__init__(embedding_dim, vocab_size, tagset_size, freeze)\n",
    "        \n",
    "        self.dense1 = nn.Linear(2*embedding_dim, 2*embedding_dim)\n",
    "        self.dense2 = nn.Linear(2*embedding_dim, tagset_size)\n",
    "    def forward(self, sentence):\n",
    "        \n",
    "        embedded = self.embedding(sentence)\n",
    "        lstm1_out, _ = self.lstm1(embedded)\n",
    "        dense1 = self.dense1(lstm1_out)\n",
    "        tag_space = self.dense2(dense1)\n",
    "        return tag_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models(emb_matrix, tags, device, freeze):\n",
    "    baseline = Baseline(100, len(emb_matrix), len(tags), freeze).to(device)\n",
    "    model1 = Model1(100, len(emb_matrix), len(tags), freeze).to(device)\n",
    "    model2 = Model2(100, len(emb_matrix), len(tags), freeze).to(device)\n",
    "    models = (baseline, model1, model2)\n",
    "    for m in models:\n",
    "        print(f'The {type(m).__name__} model has {count_parameters(m):,} trainable parameters')\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Baseline model has 1,227,645 trainable parameters\n",
      "The Model1 model has 1,469,245 trainable parameters\n",
      "The Model2 model has 1,267,845 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "baseline, model1, model2 = define_models(train_emb_matrix, global_tags, device, freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDocDataset(Dataset):\n",
    "    def __init__(self, dataframe, excluded_tags):\n",
    "        self.data = dataframe.doc\n",
    "        \n",
    "        self.tags_freq = {}\n",
    "        for d in self.data:\n",
    "            tags = d[1]\n",
    "            for t in tags:\n",
    "                try:\n",
    "                    self.tags_freq[t] +=1\n",
    "                except (KeyError):\n",
    "                    self.tags_freq[t] = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        words = self.data[idx][0]\n",
    "        tags = self.data[idx][1]\n",
    "        return words, tags\n",
    "    \n",
    "    def get_tags_frequencies(self, exclude_punct=False, low_to_high=False):\n",
    "        if exclude_punct:\n",
    "            return {k:v for k, v in sorted(self.tags_freq.items(), key=lambda i:i[1], reverse=not low_to_high) if k not in excluded_tags}\n",
    "        else:\n",
    "            return {k:v for k, v in sorted(self.tags_freq.items(), key=lambda i:i[1], reverse=not low_to_high)}\n",
    "\n",
    "\n",
    "train_data = CustomDocDataset(train_split, excluded_tags)\n",
    "val_data = CustomDocDataset(val_split, excluded_tags)\n",
    "test_data = CustomDocDataset(test_split, excluded_tags)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ([Pierre, Vinken, ,, 61, years, old, ,, will, ...\n",
       "1     ([Rudolph, Agnew, ,, 55, years, old, and, form...\n",
       "2     ([A, form, of, asbestos, once, used, to, make,...\n",
       "3     ([Yields, on, money-market, mutual, funds, con...\n",
       "4     ([J.P., Bolduc, ,, vice, chairman, of, W.R., G...\n",
       "                            ...                        \n",
       "95    ([The, National, Association, of, Securities, ...\n",
       "96    ([Program, traders, are, fond, of, predicting,...\n",
       "97    ([The, House, voted, to, boost, the, federal, ...\n",
       "98    ([Zenith, Data, Systems, Corp., ,, a, subsidia...\n",
       "99    ([For, six, years, ,, T., Marshall, Hahn, Jr.,...\n",
       "Name: doc, Length: 100, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split.doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "* Model evaluated using macro F1-score, computed over **all** tokens.\n",
    "* **Puncutation and symbol classes are not considered** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, gt, tag_pad_idx):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
    "    # some tags are excluded from the metric (punctuation, symbols, ..)\n",
    "    non_pad_elements = gt[torch.tensor([v not in list(tag_pad_idx.values()) for v in gt])].nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(gt[non_pad_elements])\n",
    "    return correct.sum() / gt[non_pad_elements].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(preds, targets, excluded_tags={}):    \n",
    "    if len(preds) == len(targets):\n",
    "        preds = np.asarray(preds)\n",
    "        targets = np.asarray(targets)\n",
    "        \n",
    "        return f1_score(targets, \n",
    "                        preds, \n",
    "                        average='macro',\n",
    "                        labels=[label for label in set(targets) if label not in excluded_tags.values()])\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_tags = []\n",
    "concat_preds = []\n",
    "i = 0\n",
    "for batch_idx, data in enumerate(val_loader):\n",
    "    inputs, labels = data[0], data[1]\n",
    "    tags = tag_to_idx_conv(labels, global_tags)\n",
    "    \n",
    "    sentence_idxs = word_to_idx_conv(inputs, final_vocab)\n",
    "    # print(inputs)\n",
    "    # print(sentence_idxs)\n",
    "    tag_scores = baseline(sentence_idxs)\n",
    "    # print(labels)\n",
    "    # print(tags.size())\n",
    "    # print(tag_scores.size())\n",
    "\n",
    "\n",
    "    # max_preds = tag_scores.argmax(dim = 1, keepdim = True)\n",
    "    # non_pad_elements = tags[torch.tensor([v not in list(excluded_tags.values()) for v in tags])].nonzero()\n",
    "    # correct = max_preds[non_pad_elements].squeeze(1).eq(tags[non_pad_elements])\n",
    "    \n",
    "    concat_tags.extend(tags.tolist())\n",
    "    concat_preds.extend(tag_scores.argmax(-1).tolist())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_loader, loss_function, word_vocab, tags_vocab, excluded_tags):\n",
    "    net.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0], data[1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Retrieve tags and sentence indices\n",
    "        tags = tag_to_idx_conv(labels, tags_vocab)\n",
    "        sentence_idxs = word_to_idx_conv(inputs, word_vocab)\n",
    "        \n",
    "        tag_scores = net(sentence_idxs)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_function(tag_scores, tags)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.cpu()) \n",
    "        \n",
    "        # calculate accuracy\n",
    "        acc = categorical_accuracy(tag_scores, tags, excluded_tags)\n",
    "        accuracy.append(acc)\n",
    "\n",
    "    return losses, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(net, val_loader, loss_function, word_vocab, tags_vocab, excluded_tags={}):\n",
    "    net.eval()\n",
    "    val_losses = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    # used for computing macro-f1\n",
    "    concat_tags = []\n",
    "    concat_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(val_loader):\n",
    "            inputs, labels = data[0], data[1]\n",
    "            \n",
    "            tags = tag_to_idx_conv(labels, tags_vocab)\n",
    "            sentence_idxs = word_to_idx_conv(inputs, word_vocab)\n",
    "            \n",
    "            tag_scores = net(sentence_idxs)\n",
    "\n",
    "            loss = loss_function(tag_scores, tags)\n",
    "            val_losses.append(loss.cpu()) \n",
    "            \n",
    "            acc = categorical_accuracy(tag_scores, tags, excluded_tags)\n",
    "            val_accuracy.append(acc)\n",
    "\n",
    "            # Exclude tags\n",
    "            tags = [t for t in tags.tolist() if t not in excluded_tags]\n",
    "            tag_scores = [t for t in tag_scores.argmax(-1).tolist() if t not in excluded_tags]\n",
    "\n",
    "            concat_tags.extend(tags)\n",
    "            concat_preds.extend(tag_scores)\n",
    "\n",
    "    return val_losses, val_accuracy, concat_preds, concat_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, n_epochs):\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train(model, train_loader, loss_function, final_vocab, global_tags, excluded_tags)\n",
    "        valid_loss, valid_acc, pred_tags, true_tags = validate(model, val_loader, loss_function, final_vocab, global_tags, excluded_tags)\n",
    "        \n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {torch.mean(torch.tensor(train_loss)):.3f} | Train Acc: {torch.mean(torch.tensor(train_acc))*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {torch.mean(torch.tensor(valid_loss)):.3f} | Val. Acc: {torch.mean(torch.tensor(valid_acc))*100:.2f}% | Val. Macro-F1: {macro_f1(pred_tags, true_tags, excluded_tags):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.03\n",
      "Macro-F1: 0.02\n"
     ]
    }
   ],
   "source": [
    "losses, accuracy, pred_tags, true_tags = validate(baseline, val_loader, loss_function, final_vocab, global_tags, excluded_tags)\n",
    "print(f\"Accuracy: {torch.mean(torch.tensor(accuracy)):.2f}\")\n",
    "print(f\"Macro-F1: {macro_f1(pred_tags, true_tags):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model2(\n",
       "  (embedding): Embedding(10570, 100, padding_idx=10569)\n",
       "  (lstm1): LSTM(100, 100, bidirectional=True)\n",
       "  (dense1): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (dense2): Linear(in_features=200, out_features=45, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights\n",
    "def init_weights(model):\n",
    "    for _, param in model.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "        \n",
    "baseline.apply(init_weights)\n",
    "model1.apply(init_weights)\n",
    "model2.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0121, -0.0130,  0.0431,  ..., -0.0208,  0.0371, -0.0187],\n",
       "        [ 0.0166, -0.0375, -0.0118,  ...,  0.0312, -0.0143,  0.0210],\n",
       "        [-0.1077,  0.1105,  0.5981,  ..., -0.8316,  0.4529,  0.0826],\n",
       "        ...,\n",
       "        [ 0.1687,  1.1911,  0.1745,  ..., -0.3251,  0.3670, -0.1799],\n",
       "        [-0.3244,  0.8465, -0.5692,  ..., -0.0289,  1.4115,  0.2803],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializa embedding layer with pretraining embedding matrix\n",
    "baseline.embedding.weight.data.copy_(train_emb_matrix)\n",
    "model1.embedding.weight.data.copy_(train_emb_matrix)\n",
    "model2.embedding.weight.data.copy_(train_emb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 2.021 | Train Acc: 50.19%\n",
      "\t Val. Loss: 1.166 | Val. Acc: 70.28% | Val. Macro-F1: 0.31\n",
      "Epoch: 02 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.746 | Train Acc: 81.89%\n",
      "\t Val. Loss: 0.641 | Val. Acc: 84.51% | Val. Macro-F1: 0.49\n",
      "Epoch: 03 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.422 | Train Acc: 89.87%\n",
      "\t Val. Loss: 0.453 | Val. Acc: 88.41% | Val. Macro-F1: 0.56\n",
      "Epoch: 04 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.271 | Train Acc: 93.44%\n",
      "\t Val. Loss: 0.352 | Val. Acc: 90.44% | Val. Macro-F1: 0.61\n",
      "Epoch: 05 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.188 | Train Acc: 95.32%\n",
      "\t Val. Loss: 0.301 | Val. Acc: 91.77% | Val. Macro-F1: 0.67\n",
      "Epoch: 06 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.134 | Train Acc: 96.66%\n",
      "\t Val. Loss: 0.273 | Val. Acc: 92.29% | Val. Macro-F1: 0.70\n",
      "Epoch: 07 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.096 | Train Acc: 97.63%\n",
      "\t Val. Loss: 0.259 | Val. Acc: 92.57% | Val. Macro-F1: 0.72\n",
      "Epoch: 08 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.069 | Train Acc: 98.36%\n",
      "\t Val. Loss: 0.243 | Val. Acc: 93.20% | Val. Macro-F1: 0.73\n",
      "Epoch: 09 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.051 | Train Acc: 98.65%\n",
      "\t Val. Loss: 0.240 | Val. Acc: 93.41% | Val. Macro-F1: 0.76\n",
      "Epoch: 10 | Epoch Time: 0m 4s\n",
      "\tTrain Loss: 0.037 | Train Acc: 99.12%\n",
      "\t Val. Loss: 0.248 | Val. Acc: 93.49% | Val. Macro-F1: 0.76\n"
     ]
    }
   ],
   "source": [
    "train_model(baseline, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 2.104 | Train Acc: 44.23%\n",
      "\t Val. Loss: 1.140 | Val. Acc: 70.62% | Val. Macro-F1: 0.31\n",
      "Epoch: 02 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.703 | Train Acc: 82.13%\n",
      "\t Val. Loss: 0.611 | Val. Acc: 84.38% | Val. Macro-F1: 0.49\n",
      "Epoch: 03 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.370 | Train Acc: 90.73%\n",
      "\t Val. Loss: 0.416 | Val. Acc: 89.20% | Val. Macro-F1: 0.57\n",
      "Epoch: 04 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.230 | Train Acc: 94.10%\n",
      "\t Val. Loss: 0.351 | Val. Acc: 90.06% | Val. Macro-F1: 0.63\n",
      "Epoch: 05 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.152 | Train Acc: 95.95%\n",
      "\t Val. Loss: 0.299 | Val. Acc: 92.12% | Val. Macro-F1: 0.68\n",
      "Epoch: 06 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.105 | Train Acc: 97.36%\n",
      "\t Val. Loss: 0.268 | Val. Acc: 92.64% | Val. Macro-F1: 0.73\n",
      "Epoch: 07 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.074 | Train Acc: 98.05%\n",
      "\t Val. Loss: 0.254 | Val. Acc: 93.34% | Val. Macro-F1: 0.73\n",
      "Epoch: 08 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 0.055 | Train Acc: 98.55%\n",
      "\t Val. Loss: 0.263 | Val. Acc: 93.41% | Val. Macro-F1: 0.74\n",
      "Epoch: 09 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 0.040 | Train Acc: 98.93%\n",
      "\t Val. Loss: 0.254 | Val. Acc: 93.65% | Val. Macro-F1: 0.79\n",
      "Epoch: 10 | Epoch Time: 0m 7s\n",
      "\tTrain Loss: 0.027 | Train Acc: 99.38%\n",
      "\t Val. Loss: 0.257 | Val. Acc: 93.42% | Val. Macro-F1: 0.78\n"
     ]
    }
   ],
   "source": [
    "train_model(model1, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 1.545 | Train Acc: 60.42%\n",
      "\t Val. Loss: 0.756 | Val. Acc: 80.52% | Val. Macro-F1: 0.46\n",
      "Epoch: 02 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.469 | Train Acc: 87.11%\n",
      "\t Val. Loss: 0.450 | Val. Acc: 87.50% | Val. Macro-F1: 0.57\n",
      "Epoch: 03 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.268 | Train Acc: 92.81%\n",
      "\t Val. Loss: 0.352 | Val. Acc: 90.23% | Val. Macro-F1: 0.66\n",
      "Epoch: 04 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.172 | Train Acc: 95.21%\n",
      "\t Val. Loss: 0.294 | Val. Acc: 91.61% | Val. Macro-F1: 0.72\n",
      "Epoch: 05 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.113 | Train Acc: 96.85%\n",
      "\t Val. Loss: 0.293 | Val. Acc: 91.80% | Val. Macro-F1: 0.74\n",
      "Epoch: 06 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.083 | Train Acc: 97.79%\n",
      "\t Val. Loss: 0.292 | Val. Acc: 91.93% | Val. Macro-F1: 0.77\n",
      "Epoch: 07 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.062 | Train Acc: 98.27%\n",
      "\t Val. Loss: 0.299 | Val. Acc: 91.54% | Val. Macro-F1: 0.78\n",
      "Epoch: 08 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.044 | Train Acc: 98.72%\n",
      "\t Val. Loss: 0.264 | Val. Acc: 93.08% | Val. Macro-F1: 0.78\n",
      "Epoch: 09 | Epoch Time: 0m 5s\n",
      "\tTrain Loss: 0.029 | Train Acc: 99.21%\n",
      "\t Val. Loss: 0.280 | Val. Acc: 93.03% | Val. Macro-F1: 0.77\n",
      "Epoch: 10 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.021 | Train Acc: 99.38%\n",
      "\t Val. Loss: 0.302 | Val. Acc: 92.62% | Val. Macro-F1: 0.80\n"
     ]
    }
   ],
   "source": [
    "train_model(model2, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test. Acc: 94.73%\n",
      "Baseline Test. F1: 0.88\n"
     ]
    }
   ],
   "source": [
    "_, test_acc, pred_tags, true_tags= validate(baseline, test_loader, loss_function, final_vocab, train_tags, excluded_tags)\n",
    "print(f'Baseline Test. Acc: {torch.mean(torch.tensor(test_acc))*100:.2f}%')\n",
    "print(f'Baseline Test. F1: {macro_f1(pred_tags, true_tags):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Test. Acc: 94.52%\n",
      "Model 1 Test. F1: 0.86\n"
     ]
    }
   ],
   "source": [
    "_, test_acc, pred_tags, true_tags = validate(model1, test_loader, loss_function, final_vocab, train_tags, excluded_tags)\n",
    "print(f'Model 1 Test. Acc: {torch.mean(torch.tensor(test_acc))*100:.2f}%')\n",
    "print(f'Model 1 Test. F1: {macro_f1(pred_tags, true_tags):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Test. Acc: 94.43%\n",
      "Model 2 Test. F1: 0.87\n"
     ]
    }
   ],
   "source": [
    "_, test_acc, pred_tags, true_tags = validate(model2, test_loader, loss_function, final_vocab, train_tags, excluded_tags)\n",
    "print(f'Model 2 Test. Acc: {torch.mean(torch.tensor(test_acc))*100:.2f}%')\n",
    "print(f'Model 2 Test. F1: {macro_f1(pred_tags, true_tags):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(model, sentence, word_vocab, tag_vocab):\n",
    "    # tags = token_to_idx_conv(actual_tags, tag_vocab)\n",
    "    sentence_idxs = word_to_idx_conv(sentence, word_vocab)\n",
    "    tag_scores = model(sentence_idxs)\n",
    "\n",
    "    pred_tags = tag_scores.argmax(-1)\n",
    "    \n",
    "    return idx_to_tag_conv(pred_tags, tag_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_comparison():\n",
    "    sentence, actual_tags = next(iter(test_loader))\n",
    "    actual_tags = [t[0] for t in actual_tags] #conversion to list\n",
    "\n",
    "    pred_tags = tag_sentence(baseline, sentence, final_vocab, train_tags)\n",
    "    pred_tags1 = tag_sentence(model1, sentence, final_vocab, train_tags)\n",
    "    pred_tags2 = tag_sentence(model2, sentence, final_vocab, train_tags)\n",
    "\n",
    "    b_acc = torch.mean(torch.tensor([i == j for i, j in zip(pred_tags, actual_tags)]).float())\n",
    "    m1_acc = torch.mean(torch.tensor([i == j for i, j in zip(pred_tags1, actual_tags)]).float())\n",
    "    m2_acc = torch.mean(torch.tensor([i == j for i, j in zip(pred_tags2, actual_tags)]).float())\n",
    "\n",
    "    print(f'Baseline Acc: {b_acc*100:.2f}%')\n",
    "    print(f'Model1 Acc: {m1_acc*100:.2f}%')\n",
    "    print(f'Model2 Acc: {m2_acc*100:.2f}%')\n",
    "\n",
    "    print(\"Pred. Tag\\t\\tActual Tag\\tCorrect?\\tCorrect1?\\tCorrect2?\\tToken\\n\")\n",
    "\n",
    "    for token, pred_tag, pred_tag1, pred_tag2, actual_tag in zip(sentence, pred_tags, pred_tags1, pred_tags2, actual_tags):\n",
    "        correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "        correct1 = '✔' if pred_tag1 == actual_tag else '✘'\n",
    "        correct2 = '✔' if pred_tag2 == actual_tag else '✘'\n",
    "        preds = pred_tag+','+pred_tag1+','+pred_tag2\n",
    "        print(f\"{preds}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{correct1}\\t\\t{correct2}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_support_graph(tag_freqs, lw_thresh, hgh_thresh):\n",
    "    # plot\n",
    "    _, ax = plt.subplots()\n",
    "    y = [v for v in tag_freqs.values()]\n",
    "    x = np.arange(1, len(tag_freqs.keys())+1)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('N. Tags')\n",
    "    ax.set_ylabel('Support (log)')\n",
    "\n",
    "    ax.axhline(y=lw_thresh, color='r', linestyle='--', label='Less frequent threshold')\n",
    "    ax.axhline(y=hgh_thresh, color='g', linestyle='--', label='Most frequent threshold')\n",
    "\n",
    "    ax.legend()\n",
    "    ax.plot(x, y, linewidth=3.0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precs_recall_curve(precisions, recalls):\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_xlabel('Recall')\n",
    "\n",
    "    ax.axvline(x=0.8, color='r', linestyle='--')\n",
    "    # ax.axhline(y=hgh_thresh, color='g', linestyle='--', label='Most frequent threshold')\n",
    "\n",
    "    ax.legend()\n",
    "    ax.plot(recalls, precisions, linewidth=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Acc: 93.23%\n",
      "Model1 Acc: 95.22%\n",
      "Model2 Acc: 93.63%\n",
      "Pred. Tag\t\tActual Tag\tCorrect?\tCorrect1?\tCorrect2?\tToken\n",
      "\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('The',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Bush',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('administration',)\n",
      "POS,POS,POS\t\tPOS\t\t✔\t\t✔\t\t✔\t\t(\"'s\",)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('nomination',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('of',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Clarence',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Thomas',)\n",
      "TO,TO,TO\t\tTO\t\t✔\t\t✔\t\t✔\t\t('to',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('a',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('seat',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('on',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "JJ,JJ,JJ\t\tJJ\t\t✔\t\t✔\t\t✔\t\t('federal',)\n",
      "NNS,NNS,NNS\t\tNNS\t\t✔\t\t✔\t\t✔\t\t('appeals',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('court',)\n",
      "RB,RB,RB\t\tRB\t\t✔\t\t✔\t\t✔\t\t('here',)\n",
      "VBD,VBD,VBD\t\tVBD\t\t✔\t\t✔\t\t✔\t\t('received',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('a',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('blow',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('this',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('week',)\n",
      "WRB,WRB,WRB\t\tWRB\t\t✔\t\t✔\t\t✔\t\t('when',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('American',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Bar',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Association',)\n",
      "VBD,VBD,VBD\t\tVBD\t\t✔\t\t✔\t\t✔\t\t('gave',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Mr.',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Thomas',)\n",
      "RB,RB,RB\t\tRB\t\t✔\t\t✔\t\t✔\t\t('only',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('a',)\n",
      "``,``,``\t\t``\t\t✔\t\t✔\t\t✔\t\t('``',)\n",
      "RB,JJ,JJ\t\tJJ\t\t✘\t\t✔\t\t✔\t\t('qualified',)\n",
      "'','',''\t\t''\t\t✔\t\t✔\t\t✔\t\t(\"''\",)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('rating',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "RB,RB,RB\t\tRB\t\t✔\t\t✔\t\t✔\t\t('rather',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('than',)\n",
      "``,``,``\t\t``\t\t✔\t\t✔\t\t✔\t\t('``',)\n",
      "RB,RB,RB\t\tRB\t\t✔\t\t✔\t\t✔\t\t('well',)\n",
      "JJ,VBN,RB\t\tVBN\t\t✘\t\t✔\t\t✘\t\t('qualified',)\n",
      ".,.,.\t\t.\t\t✔\t\t✔\t\t✔\t\t('.',)\n",
      "'','',''\t\t''\t\t✔\t\t✔\t\t✔\t\t(\"''\",)\n",
      "NNS,NNS,NNS\t\tNNS\t\t✔\t\t✔\t\t✔\t\t('People',)\n",
      "JJ,JJ,JJ\t\tJJ\t\t✔\t\t✔\t\t✔\t\t('familiar',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('with',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Senate',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Judiciary',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Committee',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "WDT,WDT,WDT\t\tWDT\t\t✔\t\t✔\t\t✔\t\t('which',)\n",
      "MD,MD,MD\t\tMD\t\t✔\t\t✔\t\t✔\t\t('will',)\n",
      "VB,VB,VB\t\tVB\t\t✔\t\t✔\t\t✔\t\t('vote',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('on',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('nomination',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "VBD,VBD,VBD\t\tVBD\t\t✔\t\t✔\t\t✔\t\t('said',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('some',)\n",
      "JJ,JJ,JJ\t\tJJ\t\t✔\t\t✔\t\t✔\t\t('liberal',)\n",
      "NNS,NNS,NNS\t\tNNS\t\t✔\t\t✔\t\t✔\t\t('members',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('of',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('panel',)\n",
      "VBP,VBP,VBP\t\tVBP\t\t✔\t\t✔\t\t✔\t\t('are',)\n",
      "JJ,JJ,JJ\t\tJJ\t\t✔\t\t✔\t\t✔\t\t('likely',)\n",
      "TO,TO,TO\t\tTO\t\t✔\t\t✔\t\t✔\t\t('to',)\n",
      "VB,VB,VB\t\tVB\t\t✔\t\t✔\t\t✔\t\t('question',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NNP,NNP,JJ\t\tNNP\t\t✔\t\t✔\t\t✘\t\t('ABA',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('rating',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('in',)\n",
      "NNS,NNS,NNS\t\tNNS\t\t✔\t\t✔\t\t✔\t\t('hearings',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('on',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('matter',)\n",
      ".,.,.\t\t.\t\t✔\t\t✔\t\t✔\t\t('.',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Mr.',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Thomas',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "RB,RB,RB\t\tRB\t\t✔\t\t✔\t\t✔\t\t('currently',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('chairman',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('of',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Equal',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Employment',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Opportunity',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Commission',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "MD,MD,MD\t\tMD\t\t✔\t\t✔\t\t✔\t\t('would',)\n",
      "VB,VB,VB\t\tVB\t\t✔\t\t✔\t\t✔\t\t('add',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('another',)\n",
      "JJ,JJ,JJ\t\tJJ\t\t✔\t\t✔\t\t✔\t\t('conservative',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('voice',)\n",
      "TO,TO,TO\t\tTO\t\t✔\t\t✔\t\t✔\t\t('to',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "RB,RB,RB\t\tRB\t\t✔\t\t✔\t\t✔\t\t('closely',)\n",
      "VBN,VBN,VBN\t\tVBN\t\t✔\t\t✔\t\t✔\t\t('divided',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('court',)\n",
      ".,.,.\t\t.\t\t✔\t\t✔\t\t✔\t\t('.',)\n",
      "NN,NNS,NN\t\tNNS\t\t✘\t\t✔\t\t✘\t\t('Groups',)\n",
      "VBP,VBP,VBP\t\tVBP\t\t✔\t\t✔\t\t✔\t\t('have',)\n",
      "VBN,VBN,VBN\t\tVBN\t\t✔\t\t✔\t\t✔\t\t('accused',)\n",
      "PRP,PRP,PRP\t\tPRP\t\t✔\t\t✔\t\t✔\t\t('him',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('of',)\n",
      "VBG,VBG,VBG\t\tVBG\t\t✔\t\t✔\t\t✔\t\t('advocating',)\n",
      "NNS,NNS,NNS\t\tNNS\t\t✔\t\t✔\t\t✔\t\t('policies',)\n",
      "IN,IN,IN\t\tWDT\t\t✘\t\t✘\t\t✘\t\t('that',)\n",
      "VBN,VBN,VBN\t\tVBD\t\t✘\t\t✘\t\t✘\t\t('narrowed',)\n",
      "NNS,NNS,NNS\t\tNNS\t\t✔\t\t✔\t\t✔\t\t('rights',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('of',)\n",
      "JJR,JJR,JJR\t\tJJR\t\t✔\t\t✔\t\t✔\t\t('older',)\n",
      "NNS,NNS,NN\t\tNNS\t\t✔\t\t✔\t\t✘\t\t('workers',)\n",
      "CC,CC,CC\t\tCC\t\t✔\t\t✔\t\t✔\t\t('and',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('of',)\n",
      "VBG,VBG,VBG\t\tVBG\t\t✔\t\t✔\t\t✔\t\t('ignoring',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('discrimination',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('by',)\n",
      "JJ,JJ,JJ\t\tJJ\t\t✔\t\t✔\t\t✔\t\t('large',)\n",
      "NNS,NNS,NNS\t\tNNS\t\t✔\t\t✔\t\t✔\t\t('companies',)\n",
      ".,.,.\t\t.\t\t✔\t\t✔\t\t✔\t\t('.',)\n",
      "JJ,NN,JJ\t\tCD\t\t✘\t\t✘\t\t✘\t\t('Fourteen',)\n",
      "NNS,NNS,NNS\t\tNNS\t\t✔\t\t✔\t\t✔\t\t('members',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('of',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('House',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('with',)\n",
      "VBZ,VBP,NN\t\tNN\t\t✘\t\t✘\t\t✔\t\t('jurisdiction',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('over',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NN,NNS,NN\t\tNNP\t\t✘\t\t✘\t\t✘\t\t('EEOC',)\n",
      "VBP,VBP,VBP\t\tVBP\t\t✔\t\t✔\t\t✔\t\t('have',)\n",
      "VBD,VBD,VBD\t\tVBN\t\t✘\t\t✘\t\t✘\t\t('said',)\n",
      "PRP,PRP,PRP\t\tPRP\t\t✔\t\t✔\t\t✔\t\t('they',)\n",
      "VBP,VBP,VBP\t\tVBP\t\t✔\t\t✔\t\t✔\t\t('oppose',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Mr.',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Thomas',)\n",
      "POS,POS,POS\t\tPOS\t\t✔\t\t✔\t\t✔\t\t(\"'s\",)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('nomination',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('because',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('of',)\n",
      "``,``,``\t\t``\t\t✔\t\t✔\t\t✔\t\t('``',)\n",
      "JJ,JJ,JJ\t\tJJ\t\t✔\t\t✔\t\t✔\t\t('serious',)\n",
      "NNS,NNS,NNS\t\tNNS\t\t✔\t\t✔\t\t✔\t\t('questions',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('about',)\n",
      "PRP$,PRP$,PRP$\t\tPRP$\t\t✔\t\t✔\t\t✔\t\t('his',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('judgment',)\n",
      "-LRB-,-LRB-,-LRB-\t\t-LRB-\t\t✔\t\t✔\t\t✔\t\t('-LCB-',)\n",
      "CC,CC,CC\t\tCC\t\t✔\t\t✔\t\t✔\t\t('and',)\n",
      "-RRB-,-RRB-,-RRB-\t\t-RRB-\t\t✔\t\t✔\t\t✔\t\t('-RCB-',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('respect',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('for',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('law',)\n",
      ".,.,.\t\t.\t\t✔\t\t✔\t\t✔\t\t('.',)\n",
      "'','',''\t\t''\t\t✔\t\t✔\t\t✔\t\t(\"''\",)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('A',)\n",
      "JJ,JJ,JJ\t\tJJ\t\t✔\t\t✔\t\t✔\t\t('senior',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Justice',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Department',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('official',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "RB,RB,RB\t\tRB\t\t✔\t\t✔\t\t✔\t\t('however',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "VBD,VBD,VBD\t\tVBD\t\t✔\t\t✔\t\t✔\t\t('said',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('administration',)\n",
      "VBZ,VBZ,VBZ\t\tVBZ\t\t✔\t\t✔\t\t✔\t\t('is',)\n",
      "RB,RB,RB\t\tRB\t\t✔\t\t✔\t\t✔\t\t(\"n't\",)\n",
      "VBN,VBN,VBN\t\tVBN\t\t✔\t\t✔\t\t✔\t\t('worried',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('about',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('ABA',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('rating',)\n",
      ".,.,.\t\t.\t\t✔\t\t✔\t\t✔\t\t('.',)\n",
      "``,``,``\t\t``\t\t✔\t\t✔\t\t✔\t\t('``',)\n",
      "PRP,PRP,PRP\t\tPRP\t\t✔\t\t✔\t\t✔\t\t('We',)\n",
      "VBP,VBP,VBP\t\tVBP\t\t✔\t\t✔\t\t✔\t\t(\"'re\",)\n",
      "VBD,VBN,VBN\t\tVBN\t\t✘\t\t✔\t\t✔\t\t('pleased',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('ABA',)\n",
      "RB,RB,RB\t\tVBD\t\t✘\t\t✘\t\t✘\t\t('rated',)\n",
      "PRP,PRP,PRP\t\tPRP\t\t✔\t\t✔\t\t✔\t\t('him',)\n",
      "RB,RB,JJ\t\tVBN\t\t✘\t\t✘\t\t✘\t\t('qualified',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "'','',''\t\t''\t\t✔\t\t✔\t\t✔\t\t(\"''\",)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('David',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('Runkel',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('department',)\n",
      "POS,POS,POS\t\tPOS\t\t✔\t\t✔\t\t✔\t\t(\"'s\",)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('chief',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('spokesman',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "VBD,VBD,VBD\t\tVBD\t\t✔\t\t✔\t\t✔\t\t('said',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('in',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('an',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('interview',)\n",
      ".,.,.\t\t.\t\t✔\t\t✔\t\t✔\t\t('.',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('The',)\n",
      "NNP,NNP,NNP\t\tNNP\t\t✔\t\t✔\t\t✔\t\t('ABA',)\n",
      "VBZ,VBZ,VBZ\t\tVBZ\t\t✔\t\t✔\t\t✔\t\t('gives',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('a',)\n",
      "``,``,``\t\t``\t\t✔\t\t✔\t\t✔\t\t('``',)\n",
      "RB,JJ,JJ\t\tVBN\t\t✘\t\t✘\t\t✘\t\t('qualified',)\n",
      "'','',''\t\t''\t\t✔\t\t✔\t\t✔\t\t(\"''\",)\n",
      "NN,NN,NN\t\tVBG\t\t✘\t\t✘\t\t✘\t\t('rating',)\n",
      "TO,TO,TO\t\tTO\t\t✔\t\t✔\t\t✔\t\t('to',)\n",
      "VB,NNS,NNS\t\tNNS\t\t✘\t\t✔\t\t✔\t\t('nominees',)\n",
      "PRP,PRP,PRP\t\tPRP\t\t✔\t\t✔\t\t✔\t\t('it',)\n",
      "VBZ,VBZ,VBZ\t\tVBZ\t\t✔\t\t✔\t\t✔\t\t('believes',)\n",
      "MD,MD,MD\t\tMD\t\t✔\t\t✔\t\t✔\t\t('would',)\n",
      "VB,VB,VB\t\tVB\t\t✔\t\t✔\t\t✔\t\t('perform',)\n",
      "``,``,``\t\t``\t\t✔\t\t✔\t\t✔\t\t('``',)\n",
      "RB,RB,RB\t\tRB\t\t✔\t\t✔\t\t✔\t\t('satisfactorily',)\n",
      "'','',''\t\t''\t\t✔\t\t✔\t\t✔\t\t(\"''\",)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('on',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('bench',)\n",
      ".,.,.\t\t.\t\t✔\t\t✔\t\t✔\t\t('.',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('In',)\n",
      "NNS,NN,NN\t\tNN\t\t✘\t\t✔\t\t✔\t\t('contrast',)\n",
      ",,,,,\t\t,\t\t✔\t\t✔\t\t✔\t\t(',',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NNS,NNS,NNS\t\tNNS\t\t✔\t\t✔\t\t✔\t\t('lawyers',)\n",
      "POS,POS,POS\t\tPOS\t\t✔\t\t✔\t\t✔\t\t(\"'\",)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('association',)\n",
      "VBZ,VBZ,VBZ\t\tVBZ\t\t✔\t\t✔\t\t✔\t\t('gives',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('a',)\n",
      "``,``,``\t\t``\t\t✔\t\t✔\t\t✔\t\t('``',)\n",
      "RB,RB,RB\t\tRB\t\t✔\t\t✔\t\t✔\t\t('well',)\n",
      "VBN,JJ,JJ\t\tVBN\t\t✔\t\t✘\t\t✘\t\t('qualified',)\n",
      "'','',''\t\t''\t\t✔\t\t✔\t\t✔\t\t(\"''\",)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('rating',)\n",
      "TO,TO,TO\t\tTO\t\t✔\t\t✔\t\t✔\t\t('to',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('those',)\n",
      "``,``,``\t\t``\t\t✔\t\t✔\t\t✔\t\t('``',)\n",
      "RB,RB,RB\t\tVBN\t\t✘\t\t✘\t\t✘\t\t('regarded',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('as',)\n",
      "CD,CD,CD\t\tCD\t\t✔\t\t✔\t\t✔\t\t('one',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('of',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "JJS,JJS,JJS\t\tJJS\t\t✔\t\t✔\t\t✔\t\t('best',)\n",
      "JJ,JJ,NN\t\tJJ\t\t✔\t\t✔\t\t✘\t\t('available',)\n",
      "IN,IN,IN\t\tIN\t\t✔\t\t✔\t\t✔\t\t('for',)\n",
      "DT,DT,DT\t\tDT\t\t✔\t\t✔\t\t✔\t\t('the',)\n",
      "NN,NN,NN\t\tNN\t\t✔\t\t✔\t\t✔\t\t('vacancy',)\n",
      ".,.,.\t\t.\t\t✔\t\t✔\t\t✔\t\t('.',)\n"
     ]
    }
   ],
   "source": [
    "pretty_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RBS': 3, 'WP$': 4, 'PDT': 4, 'EX': 5, 'RBR': 15, 'WP': 20, 'WRB': 24, 'JJS': 31, 'RP': 33, 'NNPS': 44, 'JJR': 59, 'WDT': 84, 'PRP$': 99, 'VBP': 134, 'POS': 152, 'MD': 167, 'PRP': 192, 'VBG': 221, 'VBZ': 280, 'CC': 366, 'VBN': 366, 'RB': 381, 'TO': 386, 'VB': 403, 'VBD': 634, 'CD': 858, 'JJ': 918, 'NNS': 941, 'DT': 1335, 'NNP': 1504, 'IN': 1630, 'NN': 2383}\n"
     ]
    }
   ],
   "source": [
    "test_tag_freq = test_data.get_tags_frequencies(exclude_punct=True, low_to_high=True)\n",
    "print(test_tag_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "less_frequent_th = 60\n",
    "most_frequent_th = 500\n",
    "print_support_graph(test_tag_freq, less_frequent_th, most_frequent_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Validation F1 on less frequent tags (< 60): 0.82\n",
      "Model 2 Test F1 on less frequent tags (< 60): 0.87\n"
     ]
    }
   ],
   "source": [
    "# F1 score on less frequent tags\n",
    "tag_to_filter = {k:v for k,v in test_tag_freq.items() if v > less_frequent_th}\n",
    "\n",
    "_, _, pred_tags, true_tags = validate(model2, val_loader, loss_function, final_vocab, train_tags, excluded_tags)\n",
    "print(f'Model 2 Validation F1 on less frequent tags (< {less_frequent_th}): {macro_f1(pred_tags, true_tags, tag_to_filter):.2f}')\n",
    "\n",
    "_, _, pred_tags, true_tags = validate(model2, test_loader, loss_function, final_vocab, train_tags, excluded_tags)\n",
    "print(f'Model 2 Test F1 on less frequent tags (< {less_frequent_th}): {macro_f1(pred_tags, true_tags, tag_to_filter):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Validation F1 on most frequent tags (> 500): 0.83\n",
      "Model 2 Test F1 on most frequent tags (> 500): 0.86\n"
     ]
    }
   ],
   "source": [
    "# F1 score on most frequent tags\n",
    "tag_to_filter = {k:v for k,v in test_tag_freq.items() if v < most_frequent_th}\n",
    "\n",
    "_, _, pred_tags, true_tags = validate(model2, val_loader, loss_function, final_vocab, train_tags, excluded_tags)\n",
    "print(f'Model 2 Validation F1 on most frequent tags (> {most_frequent_th}): {macro_f1(pred_tags, true_tags, tag_to_filter):.2f}')\n",
    "\n",
    "_, _, pred_tags, true_tags = validate(model2, test_loader, loss_function, final_vocab, train_tags, excluded_tags)\n",
    "print(f'Model 2 Test F1 on most frequent tags (> {most_frequent_th}): {macro_f1(pred_tags, true_tags, tag_to_filter):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(true_tags, pred_tags, metric_labels, metric_tags):\n",
    "\n",
    "    report = classification_report(true_tags, pred_tags, labels=metric_labels, target_names=metric_tags, zero_division=0, output_dict=True)\n",
    "    sorted_data = dict(\n",
    "        sorted(report.items(), key=lambda item: item[1]['f1-score'])\n",
    "    )\n",
    "\n",
    "    # Print the header\n",
    "    print(f\"{'':>12}{'precision':>10}{'recall':>10}{'f1-score':>10}{'support':>10}\")\n",
    "\n",
    "    last_rows = {}    \n",
    "    for key, value in sorted_data.items():\n",
    "        # I want these three at the end of the report\n",
    "        if key in ['micro avg', 'macro avg', 'weighted avg']:\n",
    "            last_rows[key] = value\n",
    "        else:\n",
    "            if value['support'] > 0:\n",
    "                print(f\"{key:<12}{value['precision']:>10.2f}{value['recall']:>10.2f}{value['f1-score']:>10.2f}{value['support']:>10}\")\n",
    "    \n",
    "   \n",
    "    precisions = [v['precision'] for k,v in sorted(report.items(), key=lambda item: item[1]['recall'])]\n",
    "    recalls = [v['recall'] for k,v in sorted(report.items(), key=lambda item: item[1]['recall'])]\n",
    "\n",
    "    precs_recall_curve(np.maximum.accumulate(precisions)[::-1], recalls)\n",
    "    \n",
    "    # print(\"\\n\")\n",
    "    # for key, value in last_rows.items():\n",
    "    #     print(f\"{key:<12}{value['precision']:>10.2f}{value['recall']:>10.2f}{value['f1-score']:>10.2f}{value['support']:>10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "PDT               0.00      0.00      0.00         4\n",
      "NNPS              0.19      0.09      0.12        44\n",
      "RBS               0.50      0.33      0.40         3\n",
      "RBR               0.55      0.40      0.46        15\n",
      "RP                0.58      0.67      0.62        33\n",
      "JJR               0.81      0.81      0.81        59\n",
      "JJ                0.83      0.84      0.83       918\n",
      "VBN               0.88      0.80      0.84       366\n",
      "VBG               0.89      0.81      0.85       221\n",
      "RB                0.86      0.86      0.86       381\n",
      "VBP               0.91      0.88      0.89       134\n",
      "NNP               0.91      0.90      0.91      1504\n",
      "NNS               0.98      0.84      0.91       941\n",
      "EX                0.83      1.00      0.91         5\n",
      "NN                0.87      0.96      0.91      2383\n",
      "JJS               0.97      0.90      0.93        31\n",
      "VBD               0.94      0.94      0.94       634\n",
      "WRB               0.96      0.92      0.94        24\n",
      "VBZ               0.93      0.97      0.95       280\n",
      "WDT               0.97      0.93      0.95        84\n",
      "VB                0.98      0.93      0.95       403\n",
      "CD                0.97      0.95      0.96       858\n",
      "IN                0.97      0.98      0.97      1630\n",
      "PRP$              1.00      0.97      0.98        99\n",
      "PRP               0.99      0.99      0.99       192\n",
      "DT                0.99      0.99      0.99      1335\n",
      "POS               0.99      0.99      0.99       152\n",
      "MD                0.99      1.00      0.99       167\n",
      "CC                1.00      1.00      1.00       366\n",
      "TO                1.00      1.00      1.00       386\n",
      "WP                1.00      1.00      1.00        20\n",
      "WP$               1.00      1.00      1.00         4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Report on test set\n",
    "metric_tags = [t for t in train_tags.keys() if t not in excluded_tags]\n",
    "metric_labels = [v for t,v in train_tags.items() if t not in excluded_tags]\n",
    "\n",
    "_, _, pred_tags, true_tags = validate(model2, test_loader, loss_function, final_vocab, train_tags)\n",
    "evaluate_classification(true_tags, pred_tags, metric_labels, metric_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "FW                0.00      0.00      0.00         2\n",
      "UH                0.00      0.00      0.00         2\n",
      "NNPS              0.28      0.10      0.15       105\n",
      "PDT               0.83      0.36      0.50        14\n",
      "LS                1.00      0.33      0.50         3\n",
      "RBR               0.57      0.57      0.57        35\n",
      "RP                0.47      0.79      0.59        43\n",
      "RBS               0.69      0.69      0.69        13\n",
      "JJR               0.88      0.78      0.82       165\n",
      "JJS               0.90      0.79      0.84        58\n",
      "VBN               0.89      0.80      0.84       737\n",
      "JJ                0.84      0.86      0.85      1924\n",
      "VBG               0.89      0.82      0.85       476\n",
      "VBP               0.85      0.88      0.87       460\n",
      "RB                0.90      0.84      0.87       951\n",
      "WDT               0.94      0.85      0.89       157\n",
      "NNS               0.98      0.83      0.90      2102\n",
      "NN                0.85      0.95      0.90      4513\n",
      "VB                0.95      0.87      0.91       956\n",
      "VBD               0.89      0.93      0.91       861\n",
      "NNP               0.91      0.93      0.92      2704\n",
      "VBZ               0.93      0.95      0.94       712\n",
      "CD                0.96      0.94      0.95      1249\n",
      "WRB               0.98      0.94      0.96        62\n",
      "EX                0.94      1.00      0.97        34\n",
      "IN                0.97      0.98      0.97      3275\n",
      "WP                0.96      1.00      0.98        80\n",
      "PRP$              0.99      0.98      0.99       258\n",
      "CC                0.99      0.98      0.99       758\n",
      "DT                0.99      0.99      0.99      2754\n",
      "MD                0.99      0.99      0.99       347\n",
      "POS               0.99      0.99      0.99       269\n",
      "PRP               0.99      0.99      0.99       570\n",
      "TO                1.00      1.00      1.00       765\n",
      "WP$               1.00      1.00      1.00         4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Report on validation set\n",
    "_, _, pred_tags, true_tags = validate(model2, val_loader, loss_function, final_vocab, train_tags)\n",
    "evaluate_classification(true_tags, pred_tags, metric_labels, metric_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
